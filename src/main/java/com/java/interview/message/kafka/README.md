####Kafka
#####总述
分区：副本冗余、伸缩、局部有序、提高吞吐量

完成首领选举时间长、占用内存多


根据保存时间和保存的数据量来进行数据的保存
超过数据量会关闭日志片段，关闭后超过预定的时间会删除掉



Kafka的Broker数量：取决于数据量，以及副本数

内存交换是啥意思



使用Key进行分区时，最好提前规划好分区，不能新增新的分区
消费者的数量不能超过分区数量否则会导致消费者闲置

再均衡：分区所有权从一个消费者转移到另外一个消费者
新增分区、消费者数量发生变化
再均衡后，每个消费者需要重新从Kafka获取Offset信息来作为Offset提交的起始

再均衡期间消费组是无法消费消息的


心跳和消息轮询
消费者是通过定期轮询来从Kafka中获取消息的

一个消费组群会有指定一个Broker作为组群协调器，用来检测消费者的心跳
第一加入消费者的消费者会成为“群主”，从协调器那里获取活跃消费者的名单，并将分区分配给各个消费者。
这个过程再进行再均衡时会打破。






###消费者
__consumer_offset主题用来记录客户段提交的偏移量
再均衡会导致分区最后一次提交的偏移量与客户段之前处理的偏移量发生不一致就会导致
消息的丢失或者重复消费


自动提交会设置一个提交的频率，如果在上一次提交之后，下一次提交之前发生再均衡，那么客户端
会重新消费已经执行但尚未提交的消息
自动提交会造成消息重复消费


手动提交分为同步提交和异步提交
同步提交（重试机制，保证消息不丢失），比较安全，可重试不会丢失数据但是会影响吞吐
异步提交，吞吐高，但不能重试，因为客户端Offset可能因为落后于服务端而导致重新消费，可以用CAS来
解决，先比较再更新   

提交失败不重试一般不会影响，因为后续总有成功提交的，但需要注意的是，在再均衡之前必须保证成功提交
否则会导致消息重复消费


每个分区会在其中一个Broker上指定一个Leader



Zookeeper
管理Broker集群、记录客户端提交的Offset信息，现在已经保存在了Kafka上
第一个加入集群的Broker会成为控制器，负责分区leader的选举，并在Zookeeper上创建一个临时节点，其它broker在创建时会发现已经存在，创建
失败，会在Zookeeper上创建一个watch对象，一旦broker发生了变化，就会通知到其它的broker。

控制器负责分区选举的broker，一旦控制器失去联系或者退出集群，其它broker会去zookeeper上创建临时节点

分区Leaders负责分区所有权的分配，分区Leader所在的broker失联或退出集群，控制器会进行分区leader的选举

kafka主要通过zookeeper来进行控制器选举，并通过watch机制来通知其它broker，通过epoch来防止脑裂


首领副本用于处理客户端的请求，跟随者副本仅同步首领副本的数据，作为冗余数据

kafka的零拷贝技术，文件从Linux操作系统文件资源直接复制到网卡中，而不经由应用，减少内核态和用户态
之间的上下文切换提高了效率



Kafka吞吐高的原因
多分区、多消费者
消息顺序追加
零拷贝技术
页缓存技术
